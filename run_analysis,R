# step 1 - Merging the train and test datasets to create a new dataset

# Merging X
x_train <- read.table("train/X_train.txt")

x_test <- read.table("test/X_test.txt")

Merged_X <- rbind(x_train, x_test)

# Merging subjects
subject_train <- read.table("train/subject_train.txt")

subject_test <- read.table("test/subject_test.txt")

Merged_Subject <- rbind(subject_train, subject_test)

# Merging Y
y_train <- read.table("train/y_train.txt")

y_test <- read.table("test/y_test.txt")

Merged_Y <- rbind(y_train, y_test)

# Step 2 - Extracting the mean and standard deviation

features <- read.table("features.txt")

indexOfFeatures <- grep("-mean\\(\\)|-std\\(\\)", features[, 2])

Merged_X <- Merged_X[, indexOfFeatures]

names(Merged_X) <- features[indexOfFeatures, 2]

names(Merged_X) <- gsub("\\(|\\)", "", names(Merged_X))

names(Merged_X) <- tolower(names(Merged_X))

# step 3 - name the activities in the data set.

activities <- read.table("activity_labels.txt")

activities[, 2] = gsub("_", "", tolower(as.character(activities[, 2])))

Merged_Y[,1] = activities[Merged_Y[,1], 2]

names(Merged_Y) <- "activity"

# step 4 - descriptive activity names.

names(Merged_Subject) <- "subject"

mergedDataSet <- cbind(Merged_Subject, Merged_Y, Merged_X)

write.table(mergedDataSet, "mergedDataSet.txt")

# step 5. Create a tidy data set with the average per variable per activity per subject.

uniqueSubjects = unique(Merged_Subject)[,1]

subjectsCount= length(unique(Merged_Subject)[,1])

activitiesCount= length(activities[,1])

colCount= dim(mergedDataSet)[2]

finalData = mergedDataSet[1:(numSubjects*numActivities), ]


row = 1
for (s in 1:numSubjects) {
    for (a in 1:numActivities) {

        finalData[row, 1] = uniqueSubjects[s]

        finalData[row, 2] = activities[a, 2]

        tmp <- mergedDataSet[mergedDataSet$subject==s & mergedDataSet$activity==activities[a, 2], ]

        finalData[row, 3:numCols] <- colMeans(tmp[, 3:numCols])

        row = row+1
    }
}

write.table(finalData, "tidy_dataset_with_averages.txt", row.name=FALSE)
